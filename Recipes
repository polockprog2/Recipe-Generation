{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5245331,"sourceType":"datasetVersion","datasetId":3052101}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================\n# GPU-OPTIMIZED SEQ2SEQ TRAINING\n# ============================\n\nimport os, gc, math, ast, re, warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSeq2SeqLM, \n    AdamW, \n    get_scheduler\n)\nfrom rouge_score import rouge_scorer\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom nltk.translate.gleu_score import sentence_gleu\nfrom sklearn.model_selection import train_test_split\n\n# ---------------------------\n# CONFIG\n# ---------------------------\nDATA_PATH = \"/kaggle/input/recipenlg/dataset/full_dataset.csv\"\nMODELS = [\n    \"t5-small\", \"t5-base\", \"facebook/bart-base\", \n    \"sshleifer/distilbart-cnn-12-6\",\n    \"distilbert-base-uncased\", \"roberta-base\"\n]\n\nFRAC = 0.1\nMAX_IN = 64\nMAX_OUT = 12\n\nBATCH_SIZE = 4\nACCUM = 2\nEPOCHS = 3\nLR = 3e-4\n\nSAVE_DIR = \"./best_gpu_models\"\n\n# ---------------------------\n# UTILITY\n# ---------------------------\ndef free():\n    gc.collect()\n    try: torch.cuda.empty_cache()\n    except: pass\n\n# ---------------------------\n# LOAD + CLEAN DATA\n# ---------------------------\ndf = pd.read_csv(DATA_PATH)\ndf.columns = [c.lower().strip() for c in df.columns]\ndf = df.dropna(subset=[\"title\", \"ner\"])\n\ndef parse(x):\n    try:\n        arr = ast.literal_eval(x)\n        arr = [str(a).lower().strip() for a in arr]\n        return \", \".join(sorted(list(set(arr))))\n    except:\n        return str(x).lower()\n\ndef clean(t):\n    t = str(t).lower()\n    t = re.sub(r\"[^a-z0-9 ]\", \" \", t)\n    return re.sub(r\"\\s+\", \" \", t).strip()\n\ndf[\"ingredients\"] = df[\"ner\"].apply(parse)\ndf[\"title\"] = df[\"title\"].apply(clean)\n\ndf = df[df[\"title\"].str.len() > 5]\ndf = df[df[\"ingredients\"].str.len() > 5]\ndf = df.sample(frac=FRAC, random_state=42).reset_index(drop=True)\n\ntrain_df, test_df = train_test_split(df, test_size=0.1, random_state=1)\ntrain_df, val_df = train_test_split(train_df, test_size=0.1, random_state=1)\n\n# ---------------------------\n# DATASET\n# ---------------------------\nclass RecipeDS(Dataset):\n    def __init__(self, df, tokenizer, max_in=64, max_out=12):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_in = max_in\n        self.max_out = max_out\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        src = \"generate title: \" + row[\"ingredients\"]\n        tgt = row[\"title\"]\n\n        x = self.tokenizer(src, max_length=self.max_in, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n        y = self.tokenizer(tgt, max_length=self.max_out, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n\n        labels = y[\"input_ids\"].squeeze()\n        labels[labels == self.tokenizer.pad_token_id] = -100\n\n        return {\n            \"input_ids\": x[\"input_ids\"].squeeze(),\n            \"attention_mask\": x[\"attention_mask\"].squeeze(),\n            \"labels\": labels\n        }\n\n# ---------------------------\n# METRICS\n# ---------------------------\nscorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\ndef rougeL(preds, refs):\n    scores = [scorer.score(a, b)[\"rougeL\"].fmeasure for a, b in zip(preds, refs)]\n    return float(np.mean(scores)) * 100\n\ndef bleu_score(preds, refs):\n    return np.mean([sentence_bleu([r.split()], p.split(), weights=(0.5,0.5)) for p,r in zip(preds, refs)])*100\n\ndef gleu_score(preds, refs):\n    return np.mean([sentence_gleu([r.split()], p.split()) for p,r in zip(preds, refs)])*100\n\n# ---------------------------\n# DEVICE\n# ---------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ---------------------------\n# TRAINING LOOP\n# ---------------------------\nresults = {}\n\nfor model_name in MODELS:\n    try:\n        print(f\"\\n=== TRAINING {model_name} ===\")\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        if tokenizer.pad_token is None:\n            tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n\n        model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n        model.resize_token_embeddings(len(tokenizer))\n\n        train_ds = RecipeDS(train_df, tokenizer, MAX_IN, MAX_OUT)\n        val_ds = RecipeDS(val_df, tokenizer, MAX_IN, MAX_OUT)\n        test_ds = RecipeDS(test_df, tokenizer, MAX_IN, MAX_OUT)\n\n        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n\n        optim = AdamW(model.parameters(), lr=LR)\n        steps = math.ceil(len(train_ds) / (BATCH_SIZE * ACCUM)) * EPOCHS\n        sched = get_scheduler(\"linear\", optimizer=optim, num_warmup_steps=0, num_training_steps=steps)\n\n        scaler = torch.cuda.amp.GradScaler()\n        best_score = -1\n        global_step = 0\n\n        for ep in range(EPOCHS):\n            model.train()\n            running_loss = 0\n\n            for i, batch in enumerate(train_loader):\n                batch = {k:v.to(device) for k,v in batch.items()}\n\n                with torch.cuda.amp.autocast():\n                    out = model(**batch)\n                    loss = out.loss / ACCUM\n\n                scaler.scale(loss).backward()\n                running_loss += out.loss.detach().cpu().item()\n\n                if (i+1) % ACCUM == 0:\n                    scaler.step(optim)\n                    scaler.update()\n                    sched.step()\n                    optim.zero_grad()\n                    global_step += 1\n\n                if (i+1) % (20*ACCUM) == 0:\n                    print(f\"Epoch {ep+1} Step {i+1} Loss {running_loss/(i+1):.4f}\")\n\n            # Validation\n            model.eval()\n            preds, refs = [], []\n            with torch.no_grad():\n                for b in val_loader:\n                    b = {k:v.to(device) for k,v in b.items()}\n                    gen = model.generate(input_ids=b[\"input_ids\"], attention_mask=b[\"attention_mask\"],\n                                         max_length=MAX_OUT+8, num_beams=4)\n                    p = tokenizer.batch_decode(gen, skip_special_tokens=True)\n                    lab = b[\"labels\"].cpu().numpy()\n                    lab[lab==-100] = tokenizer.pad_token_id\n                    r = tokenizer.batch_decode(lab, skip_special_tokens=True)\n                    preds += p\n                    refs += r\n\n            score = rougeL(preds, refs)\n            print(f\"Epoch {ep+1} | Val ROUGE-L = {score:.2f}\")\n\n            if score > best_score:\n                best_score = score\n                os.makedirs(os.path.join(SAVE_DIR, model_name.replace(\"/\", \"_\")), exist_ok=True)\n                model.save_pretrained(os.path.join(SAVE_DIR, model_name.replace(\"/\", \"_\")))\n                tokenizer.save_pretrained(os.path.join(SAVE_DIR, model_name.replace(\"/\", \"_\")))\n                print(\">>> Best model saved.\")\n\n        # Test evaluation\n        model.eval()\n        preds, refs = [], []\n        with torch.no_grad():\n            for b in test_loader:\n                b = {k:v.to(device) for k,v in b.items()}\n                gen = model.generate(input_ids=b[\"input_ids\"], attention_mask=b[\"attention_mask\"],\n                                     max_length=MAX_OUT+8, num_beams=4)\n                p = tokenizer.batch_decode(gen, skip_special_tokens=True)\n                lab = b[\"labels\"].cpu().numpy()\n                lab[lab==-100] = tokenizer.pad_token_id\n                r = tokenizer.batch_decode(lab, skip_special_tokens=True)\n                preds += p\n                refs += r\n\n        results[model_name] = {\n            \"rougeL\": rougeL(preds, refs),\n            \"bleu\": bleu_score(preds, refs),\n            \"gleu\": gleu_score(preds, refs)\n        }\n        print(f\"=== {model_name} TEST SCORES ===\", results[model_name])\n\n        free()\n\n    except Exception as e:\n        results[model_name] = {\"error\": str(e)}\n        print(f\"Model {model_name} failed:\", e)\n\nprint(\"\\n=== ALL MODELS FINISHED ===\")\nprint(results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:11:56.962628Z","iopub.execute_input":"2025-11-26T09:11:56.963276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}